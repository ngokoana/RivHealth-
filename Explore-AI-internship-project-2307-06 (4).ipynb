{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75246ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# RivHealth: A River Health Platform.\n",
    "\n",
    "### \"Safeguarding Waterways through Data-Driven Insights.\"\n",
    "\n",
    "![RivHealth Image](https://cdn.discordapp.com/attachments/1224661831981994044/1227979228776235109/rivhealth-1.jpeg?ex=662a5fc6&is=6617eac6&hm=162f88c07a1187b94613afac2de5ed05c547901be43484306a85d9425450defa&)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a2047-83e2-423b-9598-8ab2811ed5c9",
   "metadata": {},
   "source": [
    "# Project Description:\n",
    "\n",
    "River health has declined in the UK and worldwide. There is considerable public anger towards water companies for sewage discharges. While serious, these account for only about 6-8% of the issue, with pesticides and fertilizers having a greater impact, according to some estimates. Water companies have lost control of the narrative. Meanwhile, local action groups and citizen scientists possess useful data and insight. This project presents an opportunity for Sand Tech to develop a common national platform for sharing data on river health, which will factually inform the debate and stimulate evidence-based solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d139c604-6325-4621-8d20-058e9142af4b",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "\n",
    "Our mission is to become the trusted source of accurate insights in the water industry. We've noticed a lack of understanding among stakeholders about river health and its impact. This includes issues such as sewage discharges, agricultural runoff, misconnected sewers, illegal dumping, and industrial waste. To tackle this, we're developing a platform to offer a comprehensive view of river health and pinpoint pollution sources. Our aim is to empower stakeholders, including water companies, river conservation trusts, environmental agencies, farmers, and local authorities, with data-backed insights for informed decision-making and policy development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba943c-d5a4-4592-8fd6-476db2ebe5af",
   "metadata": {},
   "source": [
    "# Objective & Methodologies\n",
    "\n",
    "This project aims to develop a platform that integrates utility discharge data, citizen science data, and environmental/stakeholder groups' data and utilizes artificial intelligence (AI) and machine learning (ML) to provide meaningful insights into river health. The platform will empower stakeholders with evidence-based information to address the challenges facing river health in the UK and improve public understanding of river ecosystems.\n",
    "\n",
    "* Data acquisition through open data APIs, sensor data feeds, and citizen science portals.\n",
    "* Data storage using AWS, a cloud-based platform\n",
    "* Data cleaning, transformation, and feature engineering techniques using Python.\n",
    "* Machine learning model development using tools like scikit-learn or TensorFlow (I have to ask the Data Scientists to confirm)\n",
    "* Geospatial Analysis and data integration with tools like QGIS, PostGIS or ArcGIS.\n",
    "* Interactive visualization platforms using Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9e8f4",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Import packages and  libraries</a>\n",
    "\n",
    "<a href=#two>2. Data Loading</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Feature Engineering</a>\n",
    "\n",
    "<a href=#five>5. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39974704",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "\n",
    "## 1. Importing Packages\n",
    "\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "| ⚡ Description: Importing Packages ⚡                                                                                                    |\n",
    "| :--------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| In this section we imported the libraries\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d42ad",
   "metadata": {},
   "source": [
    "* Importing necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59111646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "import os\n",
    "import dotenv\n",
    "import datetime\n",
    "import folium\n",
    "import pyproj\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4267f83",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "\n",
    "## 2. Loading the Data\n",
    "\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "| ⚡ Description: Loading the data ⚡                                                          |\n",
    "| :------------------------------------------------------------------------------------------- |\n",
    "| In this we loaded in the data. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a4985-a85b-4c27-8e90-5737e2dd229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Locate the .env file\n",
    "dotenv_path = '../.env'\n",
    "dotenv.load_dotenv(dotenv_path)\n",
    "\n",
    "# Get AWS credentials from environment variables\n",
    "ACCESS_KEY = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "SECRET_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "S3_BUCKET_NAME = os.environ.get(\"S3_BUCKET_NAME\")\n",
    "\n",
    "# Create an s3 client\n",
    "s3_client = boto3.client(\"s3\", aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)\n",
    "\n",
    "# Function to read file from S3\n",
    "def read_s3_file(bucket_name, filepath):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        a pandas dataframe\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): \n",
    "            Name of the s3 bucket\n",
    "\n",
    "        filepath (str): \n",
    "            Path to the file in the s3 bucket \n",
    "            e.g. \"datasets/raw_data/uk_environmental_agency_data/water_quality/individual_sampling_points/TH-PCHE0004.csv\"\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_object = s3_client.get_object(Bucket=bucket_name, Key=filepath)\n",
    "    data = s3_object['Body'].read().decode('utf-8')\n",
    "    return pd.read_csv(StringIO(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd14aa5-2657-462a-a0b2-5008749694db",
   "metadata": {},
   "source": [
    "**Keys For the Datasets:**\n",
    "\n",
    "* wq: water quality\n",
    "* rl: river level\n",
    "* rfl: river flow level\n",
    "* rain: total rainfall\n",
    "* rtct: River Thame Conservation Trust\n",
    "* tw: Thames Water Company\n",
    "* da: Discharge Alerts\n",
    "* dcs: Discharge Current Status\n",
    "* long: Long format\n",
    "* wide: Wide format\n",
    "* invert_obj: Invertebrate Objects (Animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210310f2",
   "metadata": {},
   "source": [
    "* Load the dataset and perform initial exploration.\n",
    "* Display first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f2838-751f-429e-a575-03345c12a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed data\n",
    "wq = \"datasets/river_thame_preprocessed_data/EA_thame_sampling_points_water_quality_data.csv\"\n",
    "rfl = \"datasets/river_thame_preprocessed_data/river_thame_hydrology_stations_river_flow_level_wide_data.csv\"\n",
    "rl = \"datasets/river_thame_preprocessed_data/river_thame_hydrology_stations_river_level_wide_data.csv\"\n",
    "rain = \"datasets/river_thame_preprocessed_data/river_thame_hydrology_stations_total_rainfall_wide_data.csv\"\n",
    "rtct = \"datasets/river_thame_preprocessed_data/RTCT_data.csv\"\n",
    "tw_da = \"datasets/river_thame_preprocessed_data/Thames_Water_DischargeAlerts_River-Thame.csv\"\n",
    "tw_dcs = \"datasets/river_thame_preprocessed_data/Thames_Water_DischargeCurrentStatus_River-Thame.csv\"\n",
    "invert_obj_metrics_ = \"datasets/raw_data/uk_environmental_agency_data/invertebrate_object/INV_OPEN_DATA_METRICS_2024-04-08.csv\"\n",
    "invert_obj_site_ = \"datasets/raw_data/uk_environmental_agency_data/invertebrate_object/INV_OPEN_DATA_SITE_2024-04-08.csv\"\n",
    "invert_obj_taxa_ = \"datasets/raw_data/uk_environmental_agency_data/invertebrate_object/INV_OPEN_DATA_TAXA_2024-04-08.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab872aa5-6ac7-4e9f-a438-3221197e6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only preprocessed data so it does not impact memory\n",
    "wq_wide = read_s3_file(S3_BUCKET_NAME, wq)\n",
    "rfl_wide = read_s3_file(S3_BUCKET_NAME, rfl)\n",
    "rl_wide = read_s3_file(S3_BUCKET_NAME, rl)\n",
    "rain_wide = read_s3_file(S3_BUCKET_NAME, rain)\n",
    "rtct_data = read_s3_file(S3_BUCKET_NAME, rtct)\n",
    "tw_da_data = read_s3_file(S3_BUCKET_NAME, tw_da)\n",
    "tw_dcs_data = read_s3_file(S3_BUCKET_NAME, tw_dcs)\n",
    "invert_obj_metrics = read_s3_file(S3_BUCKET_NAME, invert_obj_metrics_)\n",
    "invert_obj_site = read_s3_file(S3_BUCKET_NAME, invert_obj_site_)\n",
    "invert_obj_taxa = read_s3_file(S3_BUCKET_NAME, invert_obj_taxa_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a2836-71f1-4b79-b41e-09f7e5856670",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "| ⚡ Description: Exploratory data analysis ⚡                                                             |\n",
    "| :------------------------------------------------------------------------------------------------------- |\n",
    "| In this section, we performed an in-depth analysis for the data we loaded. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510920db-21f5-4390-8169-a35087cfdd05",
   "metadata": {},
   "source": [
    "### 3.1. Water Quality.\n",
    "\n",
    "* Start by examining the dataset's structure, beginning with a review of the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516bd82-b444-4c96-8339-54c940faa081",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_wide.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b17e81-bb30-403b-a937-fefbf1d93fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_wide.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf10245-a2d5-48a6-8145-a1dd859125c1",
   "metadata": {},
   "source": [
    "####  NaN Values\n",
    "\n",
    "* It appears that there are numerous NaN values present. We will generate an image to visualize the rows containing these NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60283807-9d3c-4987-9427-42a395dcee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NaN counts in each column of wq_wide\n",
    "nan_counts = wq_wide.isnull().sum()\n",
    "\n",
    "# Plotting the NaN counts\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "nan_counts.plot(kind='barh', color='teal')\n",
    "plt.xlabel('NaN Counts')\n",
    "plt.ylabel('Columns')\n",
    "plt.title('NaN Counts in Each Column of wq_wide')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest count at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a239a2f-edbc-4052-aa64-6eadb1c9d338",
   "metadata": {},
   "source": [
    "**Working With NaN values**\n",
    "\n",
    "* We have a lot of NaN values. Let us replace the NaN values with the mean values. The mean represents the central tendency of the data, making it a natural choice for imputation if we want to maintain the overall average of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e67f61-a4cb-4e5e-aeec-d35500e7bc6c",
   "metadata": {},
   "source": [
    "#### Data Type\n",
    "\n",
    "* Before replacing missing values, we'll check the data types of each column to determine if they contain \"Int\" or \"Float\" values, enabling us to use statistical methods for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0010670-8939-4188-a4e4-2a7586383789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column\n",
    "data_type = wq_wide.dtypes\n",
    "\n",
    "# Print the data types\n",
    "print(data_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c50484-2d33-4cde-8c24-ba9df0a221be",
   "metadata": {},
   "source": [
    "####  NaN Values\n",
    "\n",
    "* Replace the NaN cells with the Mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836600f1-ad00-48e5-96cb-20650a810ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = [\"ammoniacal_nitrogen\", \"bod_atu\", \"conductivity\", \"iron\", \"nitrogen_oxidised\",\n",
    "                   \"unionised_ammonia\", \"nitrate\", \"nitrite\", \"dissolved_oxygen_%_saturation\",\n",
    "                   \"orthophosphate\", \"dissolved_oxygen_O2\", \"Phosphate\", \"solids_suspended_at_105C\",\n",
    "                   \"water_temperature_in_celsius\", \"ph\"]\n",
    "\n",
    "for column in columns_to_fill:\n",
    "    # Fill NaN values in each column with the mean of that column\n",
    "    wq_wide[column] = wq_wide[column].fillna(wq_wide[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fdd3c-1ce6-496d-b251-051715365676",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_wide.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a0716-6b25-4d7c-abca-0f874818f8b0",
   "metadata": {},
   "source": [
    "#### Statistical Summary\n",
    "\n",
    "* After addressing the missing values by imputation, we proceed to analyze the statistical summary to gain insights into the dataset's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bea80d-8c31-4fc8-94e1-e02c7da972e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_fill:\n",
    "    wq_wide[column] = wq_wide[column].fillna(wq_wide[column].mean())\n",
    "\n",
    "# Select only numerical columns excluding 'northing' and 'easting'\n",
    "numerical_columns = wq_wide.select_dtypes(include=['float64', 'int64']).drop(columns=['northing', 'easting'])\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = {\n",
    "    'count': numerical_columns.count(),\n",
    "    'mean': numerical_columns.mean(),\n",
    "    'std': numerical_columns.std(),\n",
    "    'min': numerical_columns.min(),\n",
    "    '25%': numerical_columns.quantile(0.25),\n",
    "    '50%': numerical_columns.quantile(0.5),\n",
    "    '75%': numerical_columns.quantile(0.75),\n",
    "    'max': numerical_columns.max()\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "summary_stats_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(summary_stats_df.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2673ece-3bf2-4e4a-bb35-ecb6309034b5",
   "metadata": {},
   "source": [
    "**Sample Date Time Column**\n",
    "\n",
    "* It seems that the datetime column is an object data type, we will be changing it to DateTime data type to avoid Limited Functionality and Loss of DateTime Features.\n",
    "\n",
    "* This code will convert the 'sample_date_time' column to datetime data type in the DataFrame wq_wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4d489-e522-43e0-aa09-b526aa66b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_wide['sample_date_time'] = pd.to_datetime(wq_wide['sample_date_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea633906-a6ec-4478-819a-29b3c6b5ccab",
   "metadata": {},
   "source": [
    "**Converting Eastely and Northely Coodinates to Longitutes and Latitudes**\n",
    "\n",
    "* Now to get an overview image of the River and the sampling points along the river so that we can start analysing our data indepth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637bd6f-f1a2-4318-a155-8ad8dea2d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the projection system for BNG (British National Grid) and WGS84 (standard latitude and longitude)\n",
    "bng = pyproj.Proj(init='epsg:27700')  # BNG projection\n",
    "wgs84 = pyproj.Proj(init='epsg:4326')  # WGS84 projection (standard latitude and longitude)\n",
    "\n",
    "# Function to convert easting and northing to longitude and latitude\n",
    "def convert_easting_northing_to_lon_lat(easting, northing):\n",
    "    lon, lat = pyproj.transform(bng, wgs84, easting, northing)\n",
    "    return lon, lat\n",
    "\n",
    "# Apply the conversion function to each row in the DataFrame\n",
    "wq_wide['longitude'], wq_wide['latitude'] = convert_easting_northing_to_lon_lat(wq_wide['easting'], wq_wide['northing'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a6e3b-25c2-4f63-b641-1e0c5df1a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the DataFrame with longitude and latitude columns\n",
    "print(wq_wide[['longitude', 'latitude']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e250ca6",
   "metadata": {},
   "source": [
    "#### Map of the Sample Catchment - The Thame Operational Catchment including River Thame and its Tributaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e56d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to store unique coordinates\n",
    "unique_coordinates = set()\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[wq_wide['latitude'].mean(), wq_wide['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# add thame catchment geojson data\n",
    "geojson_data='../src/thame_catchment.geojson'\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b8bc0-6dbb-4abc-8d14-76d4c51516d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to store unique coordinates\n",
    "unique_coordinates = set()\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[wq_wide['latitude'].mean(), wq_wide['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# Define sampling sites with different colors\n",
    "special_sites = ['TH-PTAE0064', 'TH-PTAE009', 'TH-PTAE0021', 'TH-PTAE0223', 'TH-PTAE0212',\n",
    "                'TH-PTAE0024', 'TH-PTAR0028', 'TH-PTAR0020', 'TH-PTAR0021', 'TH-PTAR0048',\n",
    "                'TH-PTAR0112', 'TH-PTAR0132', 'TH-PTAR0030', 'TH-PTAR0100', 'TH-PTAR0052',\n",
    "                'TH-PTAR0022', 'TH-RSN0914']\n",
    "\n",
    "# Add markers for each unique latitude and longitude point\n",
    "for index, row in wq_wide.iterrows():\n",
    "    # Check if the coordinates are unique\n",
    "    if (row['latitude'], row['longitude']) not in unique_coordinates:\n",
    "        # Create a popup with the sampling_point_notation\n",
    "        popup = folium.Popup(row['sampling_point_notation'], parse_html=True)\n",
    "        \n",
    "        # Check if the sampling point is special\n",
    "        if row['sampling_point_notation'] in special_sites:\n",
    "            # Add marker with custom color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='darkblue')).add_to(m)\n",
    "        else:\n",
    "            # Add marker with default color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup).add_to(m)\n",
    "        \n",
    "        # Add the coordinates to the set\n",
    "        unique_coordinates.add((row['latitude'], row['longitude']))\n",
    "\n",
    "\n",
    "# add thame catchment geojson data\n",
    "geojson_data='../src/thame_catchment.geojson'\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f78851-1cfd-4301-95ad-606121780f5d",
   "metadata": {},
   "source": [
    "* The map shows the catchment area, river flow, and sampling points.\n",
    "* Focus will be on sampling points nearest to the River Thame for thorough analysis.\n",
    "* Data from these points will be analyzed over time and compared to identify variations.\n",
    "\n",
    "**Sampling points include:**\n",
    "\n",
    "* TH-PTAE0064,\n",
    "TH-PTAE009,\n",
    "TH-PTAE0021,\n",
    "TH-PTAE0223,\n",
    "TH-PTAE0212\n",
    "\n",
    "* TH-PTAE0024,\n",
    "TH-PTAR0028,\n",
    "TH-PTAR0020,\n",
    "TH-PTAR0021,\n",
    "TH-PTAR0048,\n",
    "TH-PTAR0112\n",
    "\n",
    "* TH-PTAR0132,\n",
    "TH-PTAR0030,\n",
    "TH-PTAR0100,\n",
    "TH-PTAR0052,\n",
    "TH-PTAR0022,\n",
    "TH-RSM0914"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e84922",
   "metadata": {},
   "source": [
    "* Let us filter the data for select sampling points along the river to reduce the map load time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling sites with different colors\n",
    "special_sites = ['TH-PTAE0064', 'TH-PTAE009', 'TH-PTAE0021', 'TH-PTAE0223', 'TH-PTAE0212',\n",
    "                'TH-PTAE0024', 'TH-PTAR0028', 'TH-PTAR0020', 'TH-PTAR0021', 'TH-PTAR0048',\n",
    "                'TH-PTAR0112', 'TH-PTAR0132', 'TH-PTAR0030', 'TH-PTAR0100', 'TH-PTAR0052',\n",
    "                'TH-PTAR0022', 'TH-RSN0914']\n",
    "\n",
    "filtered_wq = wq_wide[wq_wide['sampling_point_notation'].isin(special_sites)]\n",
    "\n",
    "print(filtered_wq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebccaa8",
   "metadata": {},
   "source": [
    "* Now let us view the sampling points along the river on the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71adbde-4df7-446d-9704-26eb3b4bc9ad",
   "metadata": {},
   "source": [
    "###  Thame Catchment Area Map with Water Quality Sampling Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to store unique coordinates\n",
    "unique_coordinates = set()\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[wq_wide['latitude'].mean(), wq_wide['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# Add markers for each unique latitude and longitude point\n",
    "for index, row in filtered_wq.iterrows():\n",
    "    # Check if the coordinates are unique\n",
    "    if (row['latitude'], row['longitude']) not in unique_coordinates:\n",
    "        # Create a popup with the sampling_point_notation\n",
    "        popup = folium.Popup(row['sampling_point_notation'], parse_html=True)\n",
    "        \n",
    "        # Check if the sampling point is special\n",
    "        if row['sampling_point_notation'] in special_sites:\n",
    "            # Add marker with custom color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='darkblue')).add_to(m)\n",
    "        else:\n",
    "            # Add marker with default color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup).add_to(m)\n",
    "        \n",
    "        # Add the coordinates to the set\n",
    "        unique_coordinates.add((row['latitude'], row['longitude']))\n",
    "\n",
    "\n",
    "# add thame catchment geojson data\n",
    "geojson_data='../src/thame_catchment.geojson'\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2d623-f853-4a40-a2b5-325a34adc286",
   "metadata": {},
   "source": [
    "* **TH-PTAE0064 (ROWSHAM STW)** is the first sampling point we will work on since it is more upstream and it is located where the river starts. \n",
    "\n",
    "* **TH-PTAR0028 (THAME AT STONE BRIDGE, AYLESBURY)** will be the second sampling point to observe. After TH-PTAE0028 (THAME AT STONE BRIDGE, AYLESBURY).\n",
    "*  **TH-PTAR0020 (THAME ABOVE EYTHROPE LAKE)** will be the third sampling point to observe, and this will continue till we get to the last sampling point along the River Thame where it meets River Thames at DORCHESTER STW (TH-PTAE0024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97c29f-b7e4-4a05-b78b-d56b913c85dc",
   "metadata": {},
   "source": [
    "#### Determinant Against Sampling Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe2ee1-3842-4d81-b968-14c21741c7c7",
   "metadata": {},
   "source": [
    "* We will generate separate time series plots for each determinant against the various sampling points. This process involves iterating over each determinant and creating a distinct plot for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99708bd-f959-49e4-b332-0fea4c34f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold values for determinants with units\n",
    "thresholds = {\n",
    "    \"ammoniacal_nitrogen\": {\"lower\": 0, \"upper\": 1, \"unit\": \"mg/l\"},\n",
    "    \"bod_atu\": {\"lower\": 0, \"upper\": 4, \"unit\": \"mg/l\"},\n",
    "    \"iron\": {\"lower\": 0, \"upper\": 50, \"unit\": \"ug/l\"},\n",
    "    \"ph\": {\"lower\": 6.5, \"upper\": 8.5, \"unit\": \"phunits\"},\n",
    "    \"nitrogen_oxidised\": {\"lower\": 0, \"upper\": 2, \"unit\": \"mg/l\"},\n",
    "    \"nitrate\": {\"lower\": 0, \"upper\": 10, \"unit\": \"mg/l\"},\n",
    "    \"nitrite\": {\"lower\": 0, \"upper\": 1, \"unit\": \"mg/l\"},\n",
    "    \"phosphate\": {\"lower\": 0, \"upper\": 0.1, \"unit\": \"mg/l\"},\n",
    "    \"orthophosphate\": {\"lower\": 0, \"upper\": 0.1, \"unit\": \"mg/l\"},\n",
    "    \"water_temperature_in_celsius\": {\"lower\": 10, \"upper\": 25, \"unit\": \"degrees Celsius\"},\n",
    "    \"dissolved_oxygen_%_saturation\": {\"lower\": 80, \"upper\": 120, \"unit\": \"%\"},\n",
    "    \"dissolved_oxygen_O2\": {\"lower\": 5, \"upper\": 10, \"unit\": \"mg/l\"},\n",
    "    \"unionised_ammonia\": {\"lower\": 0, \"upper\": 0.5, \"unit\": \"mg/l\"},\n",
    "    \"solids_suspended_at_105C\": {\"lower\": 0, \"upper\": 50, \"unit\": \"mg/l\"},\n",
    "    \"conductivity\": {\"lower\": 100, \"upper\": 800, \"unit\": \"us/cm\"}\n",
    "}\n",
    "\n",
    "# List of sampling points and their labels\n",
    "sampling_points = {\n",
    "    'TH-PTAE0064': 'ROWSHAM STW',\n",
    "    'TH-PTAE0021': 'CUDDINGTON STW',\n",
    "    'TH-PTAE0223': 'THE OLD FISHERMAN PUBLIC HOUSE STW :SHAB',\n",
    "    'TH-PTAE0212': 'WATERSTOCK GOLF CLUB STW :WATERSTOCK',\n",
    "    'TH-PTAE0024': 'DORCHESTER STW',\n",
    "    'TH-PTAR0028': 'THAME AT STONE BRIDGE, AYLESBURY',\n",
    "    'TH-PTAR0020': 'THAME ABOVE EYTHROPE LAKE',\n",
    "    'TH-PTAR0021': 'THAME AT CUDDINGTON BRIDGE',\n",
    "    'TH-PTAR0048': 'CHEARSLEY BROOK ABOVE THAME, CHEARSLEY',\n",
    "    'TH-PTAR0112': 'LASHLAKE STREAM ABOVE SCOTSGROVE BROOK',\n",
    "    'TH-PTAR0132': 'CUTTLE BROOK AT THAME',\n",
    "    'TH-PTAR0030': 'THAME AT WHEATLEY BRIDGE',\n",
    "    'TH-PTAR0100': 'DENTON BROOK AT CHIPPINGHURST MANOR, LIT',\n",
    "    'TH-PTAR0052': 'CHALGROVE BROOK AT CHISELHAMPTON BRIDGE',\n",
    "    'TH-PTAR0022': 'THAME AT DORCHESTER BRIDGE',\n",
    "    'TH-RSM0914': 'OPPOSITE NEWINGTON HOUSE'\n",
    "}\n",
    "\n",
    "# Define determinants\n",
    "determinants = [\n",
    "    \"ammoniacal_nitrogen\", \"bod_atu\", \"conductivity\", \"iron\", \"nitrogen_oxidised\",\n",
    "    \"unionised_ammonia\", \"nitrate\", \"nitrite\", \"dissolved_oxygen_%_saturation\",\n",
    "    \"orthophosphate\", \"dissolved_oxygen_O2\",\"solids_suspended_at_105C\",\n",
    "    \"water_temperature_in_celsius\", \"ph\"\n",
    "]\n",
    "\n",
    "# Create a separate plot for each determinant\n",
    "for determinant in determinants:\n",
    "    # Create empty figure\n",
    "    fig = px.line(title=f'Time Series Plot of {determinant} for Different Sampling Points',\n",
    "                labels={'sample_date_time': 'Date', 'value': 'Value'},\n",
    "                template='plotly_white')\n",
    "    \n",
    "    # Add lines for each sampling point\n",
    "    for sample_point, label in sampling_points.items():\n",
    "        # Filter the dataframe for the current sample point\n",
    "        sample_data = wq_wide[wq_wide['sampling_point_notation'] == sample_point]\n",
    "        \n",
    "        # Plot the data\n",
    "        fig.add_scatter(x=sample_data['sample_date_time'], y=sample_data[determinant],\n",
    "                        mode='lines', name=label)\n",
    "    \n",
    "    # Add threshold lines\n",
    "    fig.add_hline(y=thresholds[determinant][\"lower\"], line_dash=\"dash\", line_color=\"red\",\n",
    "                annotation_text=f\"Lower Limit ({thresholds[determinant]['lower']} {thresholds[determinant]['unit']})\", \n",
    "                annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=thresholds[determinant][\"upper\"], line_dash=\"dash\", line_color=\"red\",\n",
    "                annotation_text=f\"Upper Limit ({thresholds[determinant]['upper']} {thresholds[determinant]['unit']})\", \n",
    "                annotation_position=\"top right\")\n",
    "    \n",
    "    # Highlight regions exceeding the upper limit in red\n",
    "    fig.update_traces(hoverinfo='skip')\n",
    "    if not sample_data.empty:\n",
    "        fig.update_layout(shapes=[\n",
    "            dict(type='rect', xref='paper', yref='y', \n",
    "                x0=0, x1=1, y0=thresholds[determinant][\"upper\"], y1=max(sample_data[determinant]),\n",
    "                fillcolor='rgba(255, 0, 0, 0.2)', layer='below', line_width=0),\n",
    "            dict(type='rect', xref='paper', yref='y', \n",
    "                x0=0, x1=1, y0=min(sample_data[determinant]), y1=thresholds[determinant][\"lower\"],\n",
    "                fillcolor='rgba(0, 0, 255, 0.2)', layer='below', line_width=0)\n",
    "        ])\n",
    "    \n",
    "    # Customize layout\n",
    "    fig.update_layout(xaxis=dict(title='Date', type='date', tickformat='%Y-%m-%d', title_text='Date'),\n",
    "                    yaxis=dict(title=f'{determinant} ({thresholds[determinant][\"unit\"]})'),\n",
    "                    hovermode='x unified',\n",
    "                    xaxis_rangeslider_visible=True,\n",
    "                    plot_bgcolor='#B2DFDB')  # Set background color\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c131897-cbbd-40c2-af2d-c5711a9e8276",
   "metadata": {},
   "source": [
    "**This is a brief summary of the determinands:**\n",
    "\n",
    "* **Solids, Suspended at 105 C Sources:** livestock, bank erosion, land cultivation, storm runoff, dredging.\n",
    "* **Dissolved Oxygen (% Saturation):** Adequate levels of dissolved oxygen are crucial for supporting aquatic life, as many organisms, including fish and macroinvertebrates, require oxygen to survive.\n",
    "* **BOD : 5 Day ATU:** Biochemical Oxygen Demand (BOD) is a test which measures the dissolved oxygen (DO) content of a sample of water, the sample is then incubated under controlled conditions (20Â°C) for 5 days and the DO content re-measured. The drop in DO is the BOD. ATU means that allyl thiourea (ATU) has been added to suppress nitrification during the course of the test.\n",
    "* **Nitrogen, Total Oxidized (as N):** TON is an essential parameter in water quality assessment because it reflects the overall nitrogen pollution in aquatic systems. Nitrogen compounds can originate from various sources such as agricultural runoff, wastewater discharges, industrial effluents, and atmospheric deposition.\n",
    "* **Orthophosphate, reactive as P:** Orthophosphate is a form of phosphorus that can contribute to eutrophication and algal blooms in rivers and lakes. Excessive orthophosphate levels can lead to nutrient pollution and degrade water quality.\n",
    "* **Iron:** Elevated iron levels can occur naturally or as a result of industrial activities. While some organisms require iron, excessive iron concentrations can be toxic to aquatic life and stain water bodies.\n",
    "* **Nitrate:** Elevated nitrate levels can indicate contamination from agricultural runoff or wastewater, which can lead to eutrophication, algal blooms, and harm to aquatic ecosystems.\n",
    "* **pH:** pH levels can affect the solubility of metals and nutrients in water, as well as the health of aquatic organisms. Extremes in pH (too acidic or too alkaline) can be detrimental to aquatic life.\n",
    "* **Nitrite:** Nitrite can be toxic to aquatic organisms, particularly at high concentrations, and can interfere with the oxygen-carrying capacity of hemoglobin in fish.\n",
    "\n",
    "**Outcome.**\n",
    "\n",
    "* From the above visual we can see that a few of the determinants keep changing in some sampling points and stable in the rest but we have a few that a  re constantly unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996aa51-50fe-48d1-a74b-4b3c4c257ce0",
   "metadata": {},
   "source": [
    "#### Determinants Parameters\n",
    "\n",
    "The next step is to understand the parameters for each determinant, categorizing values as within limits, above the limit, or below the limit, to assess river health. Below are the defined parameters for each determinant, indicating what constitutes a healthy river.\n",
    "\n",
    "#### Ammoniacal Nitrogen as N (mg/l)\n",
    "    Within limits: 0 - 1 mg/l\n",
    "    Above the required limit: > 1 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### BOD : 5 Day ATU (mg/l)\n",
    "    Within limits: 0 - 4 mg/l\n",
    "    Above the required limit: > 4 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Iron (ug/l)\n",
    "    Within limits: 200 - 1000 ug/l\n",
    "    Above the required limit: > 1000 ug/l\n",
    "    Below the limits: < 200 ug/l\n",
    "#### pH (phunits)\n",
    "    Within limits: 6.5 - 8.5 phunits\n",
    "    Above the required limit: > 8.5 phunits\n",
    "    Below the limits: < 6.5 phunits\n",
    "#### Nitrogen, Total Oxidised as N (mg/l)\n",
    "    Within limits: 0 - 2 mg/l\n",
    "    Above the required limit: > 2 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Nitrate as N (mg/l)\n",
    "    Within limits: 0 - 10 mg/l\n",
    "    Above the required limit: > 10 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Nitrite as N (mg/l)\n",
    "    Within limits: 0 - 1 mg/l\n",
    "    Above the required limit: > 1 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Phosphate :- {TIP} (mg/l)\n",
    "    Within limits: 0 - 0.1 mg/l\n",
    "    Above the required limit: > 0.1 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Orthophosphate, reactive as P (mg/l)\n",
    "    Within limits: 0 - 0.1 mg/l\n",
    "    Above the required limit: > 0.1 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Temperature of Water (cel)\n",
    "    Within limits: 10 - 25 degrees Celsius\n",
    "    Above the required limit: > 25 degrees Celsius\n",
    "    Below the limits: < 10 degrees Celsius\n",
    "#### Oxygen, Dissolved, % Saturation (%)\n",
    "    Within limits: 80 - 120%\n",
    "    Above the required limit: > 120%\n",
    "    Below the limits: < 80%\n",
    "##### Oxygen, Dissolved as O2 (mg/l)\n",
    "    Within limits: 5 - 10 mg/l\n",
    "    Above the required limit: > 10 mg/l\n",
    "    Below the limits: < 5 mg/l\n",
    "#### Ammonia un-ionised as N (mg/l)\n",
    "    Within limits: 0 - 0.5 mg/l\n",
    "    Above the required limit: > 0.5 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Solids, Suspended at 105 C (mg/l)\n",
    "    Within limits: 0 - 50 mg/l\n",
    "    Above the required limit: > 50 mg/l\n",
    "    Below the limits: < 0 mg/l\n",
    "#### Conductivity at 25 C (us/cm)\n",
    "    Within limits: 100 - 800 us/cm\n",
    "    Above the required limit: > 800 us/cm\n",
    "    Below the limits: < 100 us/cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc73e2-d868-4e1e-ad83-aa5b142b211c",
   "metadata": {},
   "source": [
    "### 3.2. Thames Water Discharge Alerts for River Thame\n",
    "\n",
    "The next dataset we're examining pertains to discharge alerts from Thames Water Company, the UK's largest water and wastewater company. Our objective is to pinpoint the discharge locations and analyze the frequency of these discharges.\n",
    "\n",
    "* Firstly lets look at the Discharge Alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01026d34-f56f-485a-847d-92c491ea63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_da_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c60bc-f960-4046-8dc0-852af36e7193",
   "metadata": {},
   "source": [
    "* Now we are going to convert the X and Y into Longitude and Latitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f679e1-590d-4730-b6b1-3e5848a1f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_da_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244fbcd-07da-44d7-a824-9c6aaf8aaa21",
   "metadata": {},
   "source": [
    "#### Plot showing discharge locations and Sampling points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c1321-efe9-4daa-aa89-d7e8befd1151",
   "metadata": {},
   "source": [
    "* Let's create a plot showing the discharge locations alongside the identified sampling points near the River Thame and in the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731e3b6-09d0-4fd2-92bc-50acf49ab8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the projection system for BNG (British National Grid) and WGS84 (standard latitude and longitude)\n",
    "bng = pyproj.Proj(init='epsg:27700')  # BNG projection\n",
    "wgs84 = pyproj.Proj(init='epsg:4326')  # WGS84 projection (standard latitude and longitude)\n",
    "\n",
    "# Function to convert X and Y to longitude and latitude\n",
    "def convert_X_Y_to_lon_lat(X, Y):\n",
    "    lon, lat = pyproj.transform(bng, wgs84, X, Y)\n",
    "    return lon, lat\n",
    "\n",
    "# Apply the conversion function to each row in the DataFrame\n",
    "tw_da_data['longitude'], tw_da_data['latitude'] = convert_X_Y_to_lon_lat(tw_da_data['X'], tw_da_data['Y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ffa1f",
   "metadata": {},
   "source": [
    "* Let's create a plot showing the discharge locations alongside the identified sampling points near the River Thame and in the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667edbfd-50f7-41a8-ac9c-4470e28abcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to store unique coordinates\n",
    "unique_coordinates = set()\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[wq_wide['latitude'].mean(), wq_wide['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# Add markers for each unique latitude and longitude point\n",
    "for index, row in filtered_wq.iterrows():\n",
    "    # Check if the coordinates are unique\n",
    "    if (row['latitude'], row['longitude']) not in unique_coordinates:\n",
    "        # Create a popup with the sampling_point_notation\n",
    "        popup = folium.Popup(row['sampling_point_notation'], parse_html=True)\n",
    "        \n",
    "        # Check if the sampling point is special\n",
    "        if row['sampling_point_notation'] in special_sites:\n",
    "            # Add marker with custom color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='darkblue')).add_to(m)\n",
    "        else:\n",
    "            # Add marker with default color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup).add_to(m)\n",
    "        \n",
    "        # Add the coordinates to the set\n",
    "        unique_coordinates.add((row['latitude'], row['longitude']))\n",
    "\n",
    "# Filter the DataFrame to include only unique discharge points\n",
    "unique_discharge_points = tw_da_data[tw_da_data['AlertType'].isin(['Start', 'Stop'])].drop_duplicates(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Add markers for each unique discharge point\n",
    "for index, row in unique_discharge_points.iterrows():\n",
    "    # Create a popup with the alert type and datetime\n",
    "    popup = folium.Popup(f\"Alert Type: {row['LocationName']}, DateTime: {row['DateTime']}\", parse_html=True)\n",
    "    \n",
    "    # Add marker with red color for discharge points\n",
    "    folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='red')).add_to(m)\n",
    "\n",
    "\n",
    "# add thame catchment geojson data\n",
    "geojson_data='../src/thame_catchment.geojson'\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68781dd3-7771-48e7-8389-44ee6d8996a4",
   "metadata": {},
   "source": [
    "* From the visual, we can spot around 25 discharge points scattered across the map. Some are near the river, while others are close to the sampling points along the river. Now, let's zoom in on the discharge point that releases the most water. This will help us understand its importance in the river system and what it means for water quality and how we manage wastewater."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57aae1-29c6-4193-8b55-1c62dd166f19",
   "metadata": {},
   "source": [
    "#### Bar Graph of the frequency of discharges at different locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2173eec-3cac-4043-8e87-f6aa3186be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the frequency of each unique location by two\n",
    "location_frequency = tw_da_data['LocationName'].value_counts() / 2\n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.figure(figsize=(12, 6), facecolor='#B2DFDB')  # Setting the figure size and background color\n",
    "bars = location_frequency.plot(kind='bar', color='#325d79')  # Creating the bar plot with specified color\n",
    "bars.set_facecolor('#B2DFDB')  # Setting the face color of the bars to match the background\n",
    "plt.title('Frequency of Discharges by Location', color='teal')  # Setting the title\n",
    "plt.xlabel('Location Name', color='teal')  # Setting the x-axis label\n",
    "plt.ylabel('Frequency of Discharge', color='teal')  # Setting the y-axis label\n",
    "plt.xticks(rotation=45, ha='right', color='teal')  # Rotating and aligning x-axis labels\n",
    "plt.yticks(fontsize=12, color='teal')  # Setting the font size and color of y-axis ticks\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Adding horizontal grid lines\n",
    "plt.tight_layout()  # Adjusting layout\n",
    "plt.show()  # Displaying the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb98a3-fae6-4928-a3ab-161fcccef2e3",
   "metadata": {},
   "source": [
    "* Based on the Frequency of Discharges by Location visual, it's evident that Chinnor, Stone, Worminghall, and Wingrave have experienced the highest discharges over the past three years. Consequently, our focus will be on examining the sampling points in proximity to these areas, namely TH-PTAE0020 (Chinnor), TH-PTAE0071 (Stone), TH-PTAE0092 (Worminghall), and TH-PTAR0087 (Wingrave). Our objective is to assess whether these discharge activities have had any discernible impact on the determinants observed at these sampling points. By analyzing the determinants in these areas, we aim to gain insights into the potential effects of discharge on water quality parameters and environmental conditions, thereby informing targeted interventions and management strategies to address any identified issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c0115-e585-419b-8f52-8c0b8087d6de",
   "metadata": {},
   "source": [
    "#### Determinant Chart, with each plot comparing the four sampling points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196c54f-b711-409d-b895-ffacb402a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold values for determinants with units\n",
    "thresholds = {\n",
    "    \"ammoniacal_nitrogen\": {\"lower\": 0, \"upper\": 1, \"unit\": \"mg/l\"},\n",
    "    \"bod_atu\": {\"lower\": 0, \"upper\": 4, \"unit\": \"mg/l\"},\n",
    "    \"solids_suspended_at_105C\": {\"lower\": 0, \"upper\": 50, \"unit\": \"mg/l\"}\n",
    "}\n",
    "\n",
    "# Sampling points and their labels\n",
    "sampling_points = {\n",
    "    'TH-PTAE0020': 'Chinnor',\n",
    "    'TH-PTAE0071': 'Stone',\n",
    "    'TH-PTAE0092': 'Worminghall',\n",
    "    'TH-PTAR0087': 'Wingrave'\n",
    "}\n",
    "\n",
    "# Define colors for the line plots\n",
    "colors = {'Chinnor': 'grey', 'Stone': 'pink'}\n",
    "\n",
    "# Define determinants\n",
    "determinants = [\n",
    "    \"ammoniacal_nitrogen\", \"bod_atu\", \"solids_suspended_at_105C\",\n",
    "]\n",
    "\n",
    "# Filter data for the range of interest (from 2022 to current date)\n",
    "start_date = datetime.datetime(2022, 1, 1)\n",
    "end_date = datetime.datetime.now()\n",
    "wq_wide_filtered = wq_wide[(wq_wide['sample_date_time'] >= start_date) & (wq_wide['sample_date_time'] <= end_date)]\n",
    "\n",
    "# Create a separate plot for each determinant\n",
    "for determinant in determinants:\n",
    "    # Create empty figure\n",
    "    fig = px.line(title=f'Time Series Plot of {determinant} for Different Sampling Points',\n",
    "                  labels={'sample_date_time': 'Date', 'value': f'Value ({thresholds[determinant][\"unit\"]})'},\n",
    "                  template='plotly_white')\n",
    "    \n",
    "    # Add lines for each sampling point\n",
    "    for sample_point, label in sampling_points.items():\n",
    "        # Filter the dataframe for the current sample point\n",
    "        sample_data = wq_wide_filtered[wq_wide_filtered['sampling_point_notation'] == sample_point]\n",
    "        \n",
    "        # Plot the data for the current determinant with different colors\n",
    "        if label in colors:\n",
    "            fig.add_scatter(x=sample_data['sample_date_time'], y=sample_data[determinant],\n",
    "                            mode='lines', name=label, line=dict(color=colors[label]))\n",
    "        else:\n",
    "            fig.add_scatter(x=sample_data['sample_date_time'], y=sample_data[determinant],\n",
    "                            mode='lines', name=label)\n",
    "    \n",
    "    # Add threshold lines\n",
    "    fig.add_hline(y=thresholds[determinant][\"lower\"], line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Lower Limit ({thresholds[determinant]['lower']} {thresholds[determinant]['unit']})\", \n",
    "                  annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=thresholds[determinant][\"upper\"], line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Upper Limit ({thresholds[determinant]['upper']} {thresholds[determinant]['unit']})\", \n",
    "                  annotation_position=\"top right\")\n",
    "    \n",
    "    # Customize layout with background color\n",
    "    fig.update_layout(xaxis=dict(title='Date', type='date', tickformat='%Y-%m-%d'),\n",
    "                      yaxis=dict(title=f'Value ({thresholds[determinant][\"unit\"]})'),\n",
    "                      hovermode='x unified',\n",
    "                      xaxis_rangeslider_visible=True,\n",
    "                      plot_bgcolor='#B2DFDB')  # Set background color\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c0c37-a8c1-4bd5-a58f-7c05724dcc77",
   "metadata": {},
   "source": [
    "* The visual analysis reveals that several determinants, namely ammoniacal nitrogen, BOD (biochemical oxygen demand), and suspended solids at 105°C, exhibit notable variations and occasionally surpass established thresholds. These fluctuations indicate potential impacts of sewage discharge on the river's water quality. Elevated levels of these determinants suggest contamination and reduced water quality, highlighting the influence of sewage discharge on the river's ecological health. Such findings underscore the need for effective management strategies to mitigate the adverse effects of sewage discharge on water quality and safeguard the integrity of the river ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af747d98-f956-4449-94d1-25eb09589d5d",
   "metadata": {},
   "source": [
    "* This code generate separate time series plots for each determinant, with each plot comparing the four sampling points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc83cc-2559-4d3a-8c2c-d205ec0b6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specific columns\n",
    "tw_da_data = tw_da_data[['LocationName', 'AlertType', 'DateTime']]\n",
    "\n",
    "# Convert the 'DateTime' column to datetime objects\n",
    "tw_da_data['DateTime'] = pd.to_datetime(tw_da_data['DateTime'])\n",
    "\n",
    "# Replace string values in the 'AlertType' column\n",
    "tw_da_data['AlertType'] = tw_da_data['AlertType'].replace({'Start': 34, 'Offline start': 34, 'Stop': 30, 'Offline stop': 30})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109ba920-d644-4292-a36e-f213cdfb19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for Aylesbury data and select specific columns\n",
    "aylesbury_data = tw_da_data[tw_da_data['LocationName'] == 'Aylesbury'][['LocationName', 'AlertType', 'DateTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ff587-8b73-4249-95e1-9712b747a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'DateTime' column to datetime objects\n",
    "aylesbury_data['DateTime'] = pd.to_datetime(aylesbury_data['DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e821e-98b4-4859-9c74-0e35fd1a2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace string values in the 'AlertType' column\n",
    "aylesbury_data['AlertType'] = aylesbury_data['AlertType'].replace({'Start': 34, 'Offline start': 34, 'Stop': 30, 'Offline stop': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eab690-33a2-434b-9ff5-8c0db3e306e4",
   "metadata": {},
   "source": [
    "### 3.3. River Thame Hydrology Stations Total Rainfall Wide Data\n",
    "\n",
    "* We're moving on to evaluate how rainfall variations affect river health indicators such as water quality, sedimentation rates, and aquatic biodiversity. Our aim is to understand whether increased rainfall leads to runoff pollution or erosion, influencing the overall ecological balance of the river ecosystem. To begin this analysis, we'll examine the current state of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab88e3-2a97-47a2-a978-19a6df7da16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_wide.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0512a65-1f44-4d5a-b664-4a49522dbfdd",
   "metadata": {},
   "source": [
    "* To handle missing data, we will impute all NaN values with 0 under the assumption that these instances represent days when rainfall data was not captured due to absence of rain. This approach allows for a uniform treatment of missing values, facilitating the analysis by considering non-recorded rainfall as equivalent to zero rainfall for the respective days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a525ef3-b2fa-4e21-90da-6642978a179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing all NaN values with 0\n",
    "rain_wide = rain_wide.fillna(0)\n",
    "\n",
    "# Display the first five rows of the DataFrame after replacing NaN values\n",
    "print(rain_wide.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee92a3-67aa-4b57-96e0-ccdf0d316406",
   "metadata": {},
   "source": [
    "* Looks like all the NaN values are replaced, lets then see the shape then also check the count of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335262d-1a19-42b8-ab78-7565773a0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076275e3-e21f-40f3-abd3-21c46514d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = rain_wide.isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab5cb87-09fe-494c-a558-f6a3b856aa4c",
   "metadata": {},
   "source": [
    "#### Mean Rainfall for 3 Sampling points\n",
    "* Next step is to visualise the data. The following tasks and aims to visualize the mean rainfall over the years for the three different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e1f3a-1a46-483a-8b91-6a55ec0adf17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime if it's not already\n",
    "rain_wide['date'] = pd.to_datetime(rain_wide['date'])\n",
    "\n",
    "# Extract year from the date\n",
    "rain_wide['year'] = rain_wide['date'].dt.year\n",
    "\n",
    "# Group by year and calculate the mean\n",
    "yearly_mean = rain_wide.groupby('year').mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6), facecolor='#B2DFDB')  # Setting the figure size and background color\n",
    "\n",
    "colors = ['#7DA0CA', '#052659', '#BBA9FF']  # Custom color scheme\n",
    "locations = ['Aylesbury', 'Dancers End', 'Wheatley']\n",
    "for i, column in enumerate(['aylesbury_total_rainfall', 'dancers_end_total_rainfall', 'wheatley_total_rainfall']):\n",
    "    plt.bar(yearly_mean.index + (i - 1) * 0.2, yearly_mean[column], width=0.2, label=locations[i], color=colors[i])\n",
    "\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Mean Rainfall', fontsize=12)\n",
    "plt.title('Mean Rainfall by Year and Location', fontsize=14)\n",
    "plt.xticks(yearly_mean.index, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True)\n",
    "\n",
    "# Customizing background and grid lines\n",
    "plt.gca().set_facecolor('#B2DFDB')  # Light gray background\n",
    "plt.gca().tick_params(axis='both', colors='teal')  # Change color of tick marks\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716a28b-4b18-476b-b906-e4e6586c0751",
   "metadata": {},
   "source": [
    "* This visualization helps in understanding the long-term trends and variations in rainfall for the three different locations. By plotting the mean rainfall over the years, it provides insights into how rainfall patterns have evolved and differed across various regions, but from this we can say that through the years the amount of rain is not constant but Dances End."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db0e4a3-4e5a-41e8-92ee-1bf642eb524e",
   "metadata": {},
   "source": [
    "#### Relationship Between Rainfall and Discharge\n",
    "\n",
    "* Combining discharge timelines with a line graph of rainfall helps us see how they relate. By putting them together on the same timeline, we can easily spot any patterns or connections between when it rains and when the discharge changes. This visual setup lets us quickly see if there's a link between rainfall and discharge levels. It's like putting pieces of a puzzle together to understand how rain affects the sewage discharge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa628878-03a8-4267-b22f-82c7e19324a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the Aylesbury area and all dates\n",
    "Aylesbury_filtered_bar = aylesbury_data\n",
    "\n",
    "# Plot the data for Aylesbury bar chart\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bar chart trace\n",
    "fig.add_trace(go.Bar(\n",
    "    x=Aylesbury_filtered_bar['DateTime'],\n",
    "    y=Aylesbury_filtered_bar['AlertType'],\n",
    "    name='Discharge',\n",
    "    marker_color='#673AB7',\n",
    "    marker_line_color='#673AB7',  # Set bar outline color\n",
    "    marker_line_width=1,  # Set bar outline width\n",
    "    width=8  # Adjust the width of the bars\n",
    "))\n",
    "\n",
    "# Filter the dataframe for the Aylesbury area and dates from 2022 to current date\n",
    "Aylesbury_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Add line chart trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Aylesbury_filtered_line['date'],\n",
    "    y=Aylesbury_filtered_line['aylesbury_total_rainfall'],\n",
    "    mode='lines',\n",
    "    name='Rainfall',\n",
    "    line=dict(color='#7DA0CA')\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Timeline of Events and Rainfall for Aylesbury',\n",
    "    xaxis=dict(title='Date/Time', type='date'),\n",
    "    yaxis=dict(title='Discharge / Rainfall'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Add zoom tool to the toolbar\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71521e1-5fff-4c86-adf4-b19a24b865b8",
   "metadata": {},
   "source": [
    "* The visual depiction underscores a notable correlation between rainfall and subsequent sewage discharge, suggesting a direct influence of precipitation on sewage system dynamics. This relationship likely arises from rainwater infiltration into aging sewer systems, compounded by urbanization-induced surface runoff. Such conditions can overwhelm sewer networks designed to handle both wastewater and stormwater, resulting in heightened sewage discharge during rainfall events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851f8df-445d-4204-bf05-bae733beebab",
   "metadata": {},
   "source": [
    "### 3.4. River Thame Hydrology Stations River Flow Level Wide\n",
    "\n",
    "* Lets look at how the dataset looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d5868-481b-4b92-87eb-eec60fb85170",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfl_wide.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180eeda-f9f5-4472-82a8-ee92dcc16fe1",
   "metadata": {},
   "source": [
    "#### NaN Values\n",
    "\n",
    "* It looks like we have some NaN values on the data set, we will be replace them with the mean on each sample column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5a9eb-2c29-401e-9a25-31994a1dea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = rfl_wide.isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338ede6-3a1f-4580-b765-c9be1f087494",
   "metadata": {},
   "source": [
    "* Since we have the mean river flow having zero NaN values we are then going to drop the oth two columns and keep the mean river flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb233a1-2977-4cf5-b5a2-e08d086c2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns 'wheatley_max_river_flow_level' and 'wheatley_min_river_flow_level'\n",
    "rfl_wide = rfl_wide.drop(columns=['wheatley_max_river_flow_level', 'wheatley_min_river_flow_level'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a9455-1888-431b-ac21-b7b3e9e46c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfl_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca8412-2f1c-4263-ba1a-4773b8418307",
   "metadata": {},
   "source": [
    "* Now that our data appears to be well-organized, our next step is to create visuals that illustrate the influence of river flow on the river, as well as identify other factors that impact river flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1422d-7b46-4387-b5d1-a5cc510594f5",
   "metadata": {},
   "source": [
    "#### Donut chart to visualize the average river flow level by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376835e-9113-47da-95ce-1c83d0a46605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format\n",
    "rfl_wide['date'] = pd.to_datetime(rfl_wide['date'])\n",
    "\n",
    "# Define the seasons\n",
    "def get_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "\n",
    "# Extract the month from the date\n",
    "rfl_wide['month'] = rfl_wide['date'].dt.month\n",
    "\n",
    "# Map the month to the corresponding season\n",
    "rfl_wide['season'] = rfl_wide['month'].apply(get_season)\n",
    "\n",
    "# Calculate the average river flow level for each season\n",
    "seasonal_avg_flow = rfl_wide.groupby('season')['wheatley_mean_river_flow_level'].mean()\n",
    "\n",
    "# Plot the donut chart with percentages outside the pie chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "wedges, texts, autotexts = ax.pie(seasonal_avg_flow, labels=seasonal_avg_flow.index, autopct='%1.1f%%', colors=['#ff9999','#66b3ff','#99ff99','#ffcc99'], wedgeprops=dict(width=0.4, edgecolor='teal', linewidth=3), textprops={'fontsize': 12, 'color': 'teal'}, radius=0.71)\n",
    "\n",
    "# Set edge color of each wedge to match the line color\n",
    "for wedge in wedges:\n",
    "    wedge.set_edgecolor('teal')\n",
    "\n",
    "plt.title('Average River Flow Level by Season', color='teal')  # Change color of title\n",
    "plt.ylabel('')  # Remove y-axis label\n",
    "\n",
    "# Set background color\n",
    "fig.patch.set_facecolor('#B2DFDB')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db44e42-90ab-43fa-b52c-7735ce4ba33b",
   "metadata": {},
   "source": [
    "**The outcomes of the average river flow level by season indicate interesting patterns that can provide insights into factors affecting river health:**\n",
    "\n",
    "* **Winter (48.3%):**\n",
    "   - During winter, the River Thame may experience higher flow levels due to increased rainfall, which is common during the winter months in the UK.\n",
    "   - Higher river flow during winter can result from heavy rainfall events, saturated soils, and runoff from urban and agricultural areas.\n",
    "   - Increased river flow in winter may lead to the mobilization of pollutants from land surfaces and drainage systems into the river, affecting water quality.\n",
    "\n",
    "* **Spring (24.6%):**\n",
    "   - Spring in the UK sees moderate river flow levels as a result of continued rainfall and melting of winter snow in upland areas.\n",
    "   - Higher river flow during spring can help replenish groundwater levels, support aquatic habitats, and maintain ecosystem functions.\n",
    "   - Spring runoff may transport sediment, nutrients, and pollutants from agricultural areas and urban runoff into the river, influencing water quality.\n",
    "\n",
    "*  **Autumn (17.5%):**\n",
    "   - Autumn in the UK typically experiences decreasing river flow levels as precipitation becomes less frequent and vegetation enters dormancy.\n",
    "   - Lower river flow during autumn may result in reduced dilution of pollutants and increased concentration of contaminants in the river water.\n",
    "   - Autumnal leaf fall and decaying organic matter may contribute to nutrient loading and organic pollution in the river, impacting water quality.\n",
    "\n",
    "* **Summer (9.6%):**\n",
    "   - Summer in the UK often sees the lowest river flow levels due to reduced rainfall, higher temperatures, and increased evaporation.\n",
    "   - Low river flow during summer can lead to water scarcity issues, particularly in areas with high water demand for agriculture and domestic use.\n",
    "   - Summer drought conditions may stress aquatic ecosystems, reduce habitat availability for fish and other species, and exacerbate water quality issues such as algal blooms and nutrient enrichment.\n",
    "\n",
    "In **summary**, while snowfall may not be a significant factor affecting river flow levels in the UK, seasonal variations in rainfall and temperature still play a crucial role in influencing water flow dynamics and water quality in rivers like the Thame. Understanding these seasonal patterns is essential for managing and protecting river ecosystems and ensuring sustainable water resource management in the region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82202b12-af68-4472-9cbb-06ddd0fb6e40",
   "metadata": {},
   "source": [
    "### Relationship between River Flow and Rain\n",
    "\n",
    "* Now in the next visual we want to see if rain has any influence on the flow of the river."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60093a-0c64-4cee-aa3b-299288abaf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the Wheatley area and all dates\n",
    "wheatley_filtered = rfl_wide\n",
    "\n",
    "# Filter the dataframe for the Aylesbury area and dates from 2022 to current date\n",
    "Wheatley_filtered = rain_wide\n",
    "# Create line charts for both datasets\n",
    "fig = px.line()\n",
    "\n",
    "# Add line for wheatley_mean_river_flow_level\n",
    "fig.add_scatter(x=wheatley_filtered['date'], y=wheatley_filtered['wheatley_mean_river_flow_level'], \n",
    "                mode='lines', name='Wheatley River Flow Level')\n",
    "\n",
    "# Add line for wheatley_total_rainfall\n",
    "fig.add_scatter(x=Wheatley_filtered['date'], y=Wheatley_filtered['wheatley_total_rainfall'], \n",
    "                mode='lines', name='Wheately Rainfall', line_color='#7DA0CA')\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Comparison of River Flow Level and Rainfall',\n",
    "    xaxis=dict(title='Date', type='date', tickformat='%Y-%m-%d'),\n",
    "    yaxis=dict(title='Value'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ed4a5-bda7-4b3e-bec4-01e7c339c811",
   "metadata": {},
   "source": [
    "**Seasonal Impact on River Flow:**\n",
    "\n",
    "* **June to November:** River flow remains largely unaffected by rainfall.\n",
    "November to May: River flow aligns closely with rainfall, showing significant influence.\n",
    "\n",
    "* **River Health Implications:**\n",
    "    - Dry Months (June to November):  Reduced water levels and stress on aquatic ecosystems.\n",
    "     - Wetter Months (November to May): Higher river flow risks erosion, sedimentation, and water quality changes.\n",
    "  \n",
    "* **Importance for River Management:**\n",
    "    - Understanding rainfall and river flow dynamics is crucial for assessing and managing river health.\n",
    "    Enables informed decisions to sustain ecological balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b476b-2f56-48ae-844e-c9afa5650f64",
   "metadata": {},
   "source": [
    "### 3.5. RTCT/ Citizen Scientist Data\n",
    "\n",
    "* Lets look at how the dataset looks. Maybe the data from the Citizen Data might also help us get more insight into the enviroments we are working on ant the behavour of our determinants. Firstly we need to view the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc23840-c9d7-4b46-86fd-f3aad696ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = rtct_data.isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45621633-fff6-447b-b62e-42c69b211505",
   "metadata": {},
   "source": [
    "* The data seems to look at a lot of determinants, most of we may not be able to use and we will then not be working with some columns. But for now we are going to look at the locations that the Scientist used to take samples and decide fromhere if we can use all the data or focus on specific locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed59ea-f3b2-4524-add1-0c7e338e1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to store unique coordinates\n",
    "unique_coordinates = set()\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[51.762056, -0.975278], zoom_start=10)\n",
    "\n",
    "# Create feature groups for each dataset\n",
    "tw_da_group = folium.FeatureGroup(name='tw_da_data (Red)')\n",
    "wq_wide_group = folium.FeatureGroup(name='wq_wide (Blue)')\n",
    "rtct_group = folium.FeatureGroup(name='rtct_data (Green)')\n",
    "\n",
    "# Define sampling sites with different colors\n",
    "special_sites = ['TH-PTAE0064', 'TH-PTAE009', 'TH-PTAE0021', 'TH-PTAE0223', 'TH-PTAE0212',\n",
    "                 'TH-PTAE0024', 'TH-PTAR0028', 'TH-PTAR0020', 'TH-PTAR0021', 'TH-PTAR0048',\n",
    "                 'TH-PTAR0112', 'TH-PTAR0132', 'TH-PTAR0030', 'TH-PTAR0100', 'TH-PTAR0052',\n",
    "                 'TH-PTAR0022', 'TH-RSN0914']\n",
    "\n",
    "# Create a set to store unique special sites\n",
    "unique_special_sites = set()\n",
    "\n",
    "# Filter wq_wide data to include only unique special_sites\n",
    "for index, row in wq_wide.iterrows():\n",
    "    if row['sampling_point_notation'] in special_sites and row['sampling_point_notation'] not in unique_special_sites:\n",
    "        popup = folium.Popup(row['sampling_point_notation'], parse_html=True)\n",
    "        folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='darkblue')).add_to(wq_wide_group)\n",
    "        unique_special_sites.add(row['sampling_point_notation'])\n",
    "\n",
    "# Filter the DataFrame to include only unique discharge points\n",
    "unique_discharge_points = tw_da_data[tw_da_data['AlertType'].isin(['Start', 'Stop'])].drop_duplicates(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Add markers for each unique discharge point\n",
    "for index, row in unique_discharge_points.iterrows():\n",
    "    # Create a popup with the alert type and datetime\n",
    "    popup = folium.Popup(f\"Alert Type: {row['LocationName']}, DateTime: {row['DateTime']}\", parse_html=True)\n",
    "    \n",
    "    # Add marker with red color for discharge points\n",
    "    folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='red')).add_to(tw_da_group)\n",
    "\n",
    "# Define specified site names for rtct_data\n",
    "rtct_specified_sites = [\n",
    "    'Lower Thame at Chippinghurst', 'Mid Thame below Long Crendon STW', 'Upper Thame ALL',\n",
    "    'Upper Thame Below Tring STW', 'Lower Thame at Ickford', 'Lower Thame at Shabbington',\n",
    "    'Lower Thame below Wheatley STW', 'Lower Thame ALL', 'Cuddington bridge',\n",
    "    'Nether Winchendon Footbridge', 'Mid Thame below cuddington STW',\n",
    "    'Lower Thame below G Milton STW', 'Lower Thame Dorchester'\n",
    "]\n",
    "\n",
    "# Filter rtct_data based on the unique specified site names\n",
    "filtered_rtct_data = rtct_data[rtct_data['Site Name'].isin(rtct_specified_sites)]\n",
    "\n",
    "# Convert rtct_specified_sites to a set to remove duplicates\n",
    "rtct_specified_sites_set = set(rtct_specified_sites)\n",
    "\n",
    "# Create a dictionary to store main land use within 50m for each site\n",
    "land_use_dict = dict(zip(rtct_data['Site Name'], rtct_data['What is the main land use within 50m?']))\n",
    "\n",
    "# Iterate over filtered_rtct_data to add markers for unique site names\n",
    "for index, row in filtered_rtct_data.iterrows():\n",
    "    # Check if the Site Name is in the set of unique specified sites\n",
    "    if row['Site Name'] in rtct_specified_sites_set:\n",
    "        # Get the main land use within 50m for the site\n",
    "        land_use = land_use_dict.get(row['Site Name'], 'Unknown')\n",
    "        # Create popup content with site name and land use\n",
    "        popup_content = f\"{row['Site Name']}Main land use within 50m: {land_use}\"\n",
    "        folium.Marker(\n",
    "            [row['y'], row['x']],\n",
    "            icon=folium.Icon(color='green'),\n",
    "            popup=folium.Popup(popup_content, parse_html=True)\n",
    "        ).add_to(rtct_group)\n",
    "\n",
    "        # Remove the site name from the set to ensure only unique markers are added\n",
    "        rtct_specified_sites_set.remove(row['Site Name'])\n",
    "\n",
    "# Add feature groups to the map\n",
    "wq_wide_group.add_to(m)\n",
    "tw_da_group.add_to(m)\n",
    "rtct_group.add_to(m)\n",
    "\n",
    "# add thame catchment geojson data\n",
    "geojson_data='../src/thame_catchment.geojson'\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n",
    "\n",
    "# Add layer control to the map\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Display the map\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc01dd-9e32-47bc-a8dc-e9024d5d1ee2",
   "metadata": {},
   "source": [
    "* **Sampling Points Distribution:** \n",
    "  Shows the locations of water quality points (dark blue), discharge alerts (red), and river flow monitoring sites (green).\n",
    "  \n",
    "* **Special Sampling Sites:** Highlights critical water quality sites for detailed analysis.\n",
    "\n",
    "* **Discharge Alerts:** Indicates where and when discharges occur, aiding in understanding their impact on water quality.\n",
    "\n",
    "* **Land Use Information:** Displays the main land use within 50m of river flow sites, helping to identify potential pollution sources.\n",
    "\n",
    "* **Geographical Context:** The Thame catchment boundary overlay provides a spatial reference for the monitoring efforts.\n",
    "\n",
    "**Overall**, the map helps identify environmental hotspots, assess the impact of land use, understand discharge patterns, and prioritize resource allocation for effective environmental management.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed27ce9",
   "metadata": {},
   "source": [
    "a id=\"five\"></a>\n",
    "\n",
    "## 4. Feature Engineering\n",
    "\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "| ⚡ Description Feature engineering ⚡                                                                                        |\n",
    "| :------------------------------------------------------------------------------------------------------------------------- |\n",
    "| In this section added new features- as identified in the EDA phase. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae70448",
   "metadata": {},
   "source": [
    "In the upcoming feature engineering phase, we'll focus on refining our dataset to better capture the underlying patterns and relationships relevant to our problem. This involves extracting key information, transforming features for better representation, creating new features to enrich our dataset, and selecting the most informative variables to use on the POC. Through this process, we aim to enhance and improve interpretability, and ultimately achieve more accurate and reliable predictions of what is cousing our rivers to be unhealthy. Now due to some limitations we have decided to work with data from the year 2022 because some data doesnt go all the way to the year 2000, this will also help use work with less data and will help us give more current information on our platfom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8527fe-5508-43ec-a152-8cc95d6572d0",
   "metadata": {},
   "source": [
    "### 4.1. Rainfall Analysis\n",
    "\n",
    "* We're going to compare the rainfall at three places: Aylesbury, Dancers End, and Wheatley. We only have data for these spots, but we want to understand rainfall across the whole area. So, we'll start by plotting the rainfall data we have for these three places on a graph. This will help us see if there are any differences in how much rain each place gets over time. We'll use different colors for each place's data, making it easier to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f359507-0d52-449c-81fe-dc12210a1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime if it's not already in datetime format\n",
    "rain_wide['date'] = pd.to_datetime(rain_wide['date'])\n",
    "\n",
    "# Filter the DataFrame to include only data from 2022 to 2024\n",
    "rain_wide = rain_wide[(rain_wide['date'].dt.year >= 2022) & (rain_wide['date'].dt.year <= 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091f352-c9aa-48e4-97a4-287ba0bfa347",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f64dd-c394-42c1-b105-4922b84cfd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1ebaf-8910-49b9-84f9-fd15297ed36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the Aylesbury area and all dates\n",
    "Aylesbury_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Filter the dataframe for the Wheatley area and all dates\n",
    "Wheatley_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Filter the dataframe for the Dancers End area and all dates\n",
    "Dancers_End_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line chart trace for Aylesbury rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Aylesbury_filtered_line['date'],\n",
    "    y=Aylesbury_filtered_line['aylesbury_total_rainfall'],\n",
    "    mode='lines',\n",
    "    name='Aylesbury Rainfall',\n",
    "    line=dict(color='#7DA0CA')\n",
    "))\n",
    "\n",
    "# Add line chart trace for Wheatley rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Wheatley_filtered_line['date'],\n",
    "    y=Wheatley_filtered_line['wheatley_total_rainfall'],\n",
    "    mode='lines',\n",
    "    name='Wheatley Rainfall',\n",
    "    line=dict(color='#BBA9FF')\n",
    "))\n",
    "\n",
    "# Add line chart trace for Dancers End rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Dancers_End_filtered_line['date'],\n",
    "    y=Dancers_End_filtered_line['dancers_end_total_rainfall'],\n",
    "    mode='lines',\n",
    "    name='Dancers End Rainfall',\n",
    "    line=dict(color='#052659')\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Timeline of Rainfall for Aylesbury, Wheatley, and Dancers End',\n",
    "    xaxis=dict(title='Date/Time', type='date'),\n",
    "    yaxis=dict(title='Rainfall (mm)'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Add zoom tool to the toolbar\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e4a75-0de6-4317-ab0f-401678917363",
   "metadata": {},
   "source": [
    "* The visual provides a comprehensive overview of the rainfall patterns within the catchment area. It reveals a synchronized movement among the rainfall lines for Aylesbury, Wheatley, and Dancers_End, indicating a correlated pattern in rainfall occurrence across the three locations. Specifically, when rainfall occurs in Aylesbury, a similar trend is observed in Wheatley, albeit with slight variations in the amount of rainfall. Similarly, despite Dancers_End experiencing higher rainfall amounts compared to the other two locations, the visual suggests a consistent influence of rainfall across all three areas. Consequently, we have decided to retain data from all three locations and utilize the mean of their rainfall values. This approach ensures a more representative assessment of rainfall distribution within the catchment, enabling a more accurate analysis of its impact on other locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eae059-23e0-47e2-9284-b30f9fa9b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559c67c-b2c6-4349-b907-af562935b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the three rainfall columns for each row\n",
    "rain_wide['rain_mean'] = rain_wide[['aylesbury_total_rainfall', 'wheatley_total_rainfall']].mean(axis=1)\n",
    "\n",
    "# Display the DataFrame to verify the results\n",
    "print(rain_wide.head())\n",
    "\n",
    "# If you want to take the mean for each day and create a new column 'rain_mean':\n",
    "# Convert 'date' column to datetime if it's not already\n",
    "rain_wide['date'] = pd.to_datetime(rain_wide['date'])\n",
    "\n",
    "# Calculate the mean rainfall for each day\n",
    "daily_rain_mean = rain_wide.groupby('date')['rain_mean'].mean().reset_index()\n",
    "\n",
    "# Rename the column to 'rain_mean'\n",
    "daily_rain_mean = daily_rain_mean.rename(columns={'rain_mean': 'rain_mean'})\n",
    "\n",
    "# Keep only the necessary columns from daily_rain_mean DataFrame\n",
    "daily_rain_mean = daily_rain_mean[['date', 'rain_mean']]\n",
    "\n",
    "# Merge the mean rainfall data with the original DataFrame\n",
    "rain_wide = pd.merge(rain_wide, daily_rain_mean, on='date', how='left')\n",
    "\n",
    "# Drop the 'year' column\n",
    "rain_wide.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f146c9f-4ebf-4dfe-9da0-e23a23f3d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop one of the 'rain_mean' columns\n",
    "rain_wide = rain_wide.drop(columns=['rain_mean_y'])\n",
    "\n",
    "# Verify the DataFrame after dropping the column\n",
    "print(rain_wide.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfec1d-7bc6-429b-89ca-8436c8b7b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the Aylesbury area and all dates\n",
    "Aylesbury_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Filter the dataframe for the Wheatley area and all dates\n",
    "Wheatley_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Filter the dataframe for the Dancers End area and all dates\n",
    "Dancers_End_filtered_line = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line chart trace for Aylesbury rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Aylesbury_filtered_line['date'],\n",
    "    y=Aylesbury_filtered_line['aylesbury_total_rainfall'],\n",
    "    mode='lines',\n",
    "    name='Aylesbury Rainfall',\n",
    "    line=dict(color='#7DA0CA')\n",
    "))\n",
    "\n",
    "# Add line chart trace for Wheatley rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Wheatley_filtered_line['date'],\n",
    "    y=Wheatley_filtered_line['wheatley_total_rainfall'],\n",
    "    mode='lines',\n",
    "    name='Wheatley Rainfall',\n",
    "    line=dict(color='#380F66')\n",
    "))\n",
    "\n",
    "\n",
    "# Add line chart trace for the mean rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=Aylesbury_filtered_line['date'],\n",
    "    y=Aylesbury_filtered_line['rain_mean_x'],\n",
    "    mode='lines',\n",
    "    name='Mean Rainfall',\n",
    "    line=dict(color='green')  # Change color to green\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Timeline of Rainfall for Aylesbury  and  Wheatley',\n",
    "    xaxis=dict(title='Date/Time', type='date'),\n",
    "    yaxis=dict(title='Rainfall (mm)'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Add zoom tool to the toolbar\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47508f2-c6cb-4b37-96ad-e71cb35df272",
   "metadata": {},
   "source": [
    "* The visualization of the rainfall data indicates a consistent pattern across the three locations – Aylesbury, Dancers End, and Wheatley. Despite slight variations in rainfall levels at each location, the mean rainfall calculated from these datasets appears to align closely with the individual rainfall trends. This alignment suggests that the mean derived from the three datasets is reliable and representative of the overall rainfall pattern within the catchment area. Consequently, moving forward, we intend to utilize this mean rainfall value as a standard reference for analyzing data from all sampling points within the catchment area, facilitating a comprehensive analysis through facet plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f46b13-9bae-4f82-9e9d-056fd92b67ad",
   "metadata": {},
   "source": [
    "### 4.2. River Flow\n",
    "\n",
    "For the river flow data we have a small issue, we will only be using the Wheatly River Flow data for the entire catchment since its the only location that measures river flow in the catchment. \n",
    "\n",
    "River flow is not typically constant across the entire river stretch. Several factors contribute to variations in river flow, including topography, weather patterns, seasonal changes, human activities, and the presence of tributaries or diversions along the river course. For instance, in mountainous regions, river flow may vary significantly due to differences in elevation and precipitation patterns. Additionally, human interventions such as dams, irrigation withdrawals, and wastewater discharges can alter river flow patterns. Therefore, while some sections of a river may exhibit relatively stable flow rates, others may experience fluctuations depending on the prevailing conditions and anthropogenic influences.\n",
    "\n",
    "Applying river flow data from a single location to all sampling points along the river can be a useful approximation, especially when detailed flow measurements are not available for each sampling point. However, it's essential to recognize that river flow can vary spatially due to factors such as channel morphology, land use changes, and local hydrological conditions.\n",
    "\n",
    "Using river flow data from a single location assumes that flow conditions are relatively uniform along the river reach. While this approach can provide a simplified representation of flow dynamics, it may overlook localized variations that could influence water quality parameters at specific sampling points.\n",
    "\n",
    "Therefore, while applying a single river flow value to all sampling points can offer insights into general trends, it's crucial to interpret the results cautiously and consider the potential limitations of this approach. Integrating additional data sources or conducting site-specific measurements where feasible can enhance the accuracy and reliability of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03305421-d8ad-4027-bb46-2785ae5854ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime if it's not already in datetime format\n",
    "rfl_wide['date'] = pd.to_datetime(rfl_wide['date'])\n",
    "\n",
    "# Filter the DataFrame to include only data from 2022 to 2024\n",
    "rfl_wide = rfl_wide[(rfl_wide['date'].dt.year >= 2022) & (rfl_wide['date'].dt.year <= 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a79ed9-1200-497a-a5a0-4e38803e97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfl_wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fae070-11ae-407d-b120-f58c40b5d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfl_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0d42d-dda3-45d4-aaa7-aab52768d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column 'wheatley_mean_river_flow_level' to 'river_thame_river_flow_level'\n",
    "rfl_wide.rename(columns={'wheatley_mean_river_flow_level': 'river_thame_river_flow_level'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame after renaming the column\n",
    "print(rfl_wide.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540ad58-fd79-43e2-8daf-9020bb2fdbf5",
   "metadata": {},
   "source": [
    "#### River Thame Flow Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f27a7-2536-426d-823e-23953e11c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for the River Thame area and all dates\n",
    "wheatley_filtered = rfl_wide\n",
    "\n",
    "# Create line chart for the river_thame_mean_river_flow_level\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line for river_thame_mean_river_flow_level\n",
    "fig.add_scatter(x=wheatley_filtered['date'], y=wheatley_filtered['river_thame_river_flow_level'], \n",
    "                mode='lines', name='River Thame Flow Level')\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='River Thame Flow Level',\n",
    "    xaxis=dict(title='Date', type='date', tickformat='%Y-%m-%d'),\n",
    "    yaxis=dict(title='Flow Level'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352dad7f-6220-48a9-af26-0b9b6eca7730",
   "metadata": {},
   "source": [
    "* Moving forward, we will incorporate this chart along with the rest of the visuals into a facet plot. This will allow us to examine whether river flow impacts water quality, in conjunction with the Environmental Data Metrics (EDMs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79602df2-ab33-45e1-be39-998cd125d97d",
   "metadata": {},
   "source": [
    "### 4.3. Discharge Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392148d-2d16-4446-ae98-79ca400f3e5d",
   "metadata": {},
   "source": [
    "* Now, we aim to observe the discharges on each individual EDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8812f3d-764a-4cfd-8a76-8d198a920b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specific columns including 'X' and 'Y'\n",
    "tw_da_data_edm = tw_da_data[[ 'LocationName', 'AlertType', 'DateTime']]\n",
    "\n",
    "# Convert the 'DateTime' column to datetime objects\n",
    "tw_da_data_edm['DateTime'] = pd.to_datetime(tw_da_data['DateTime'])\n",
    "\n",
    "# Replace string values in the 'AlertType' column\n",
    "tw_da_data['AlertType'] = tw_da_data['AlertType'].replace({'Start': 34, 'Offline start': 0, 'Stop': 0, 'Offline stop': 0})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(tw_da_data_edm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a5958-6468-46bb-8342-883338d6e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_da_data_edm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42dca8-5650-471a-ba0c-af4ec3c2e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of location names you want to filter by\n",
    "locations = ['Cuddington', 'Dorchester', 'Aylesbury', 'Marsworth', 'Haddenham', 'Long Crendon', \n",
    "             'Shabbington', 'Stone', 'Thame', 'Wingrave', 'Stewkley', 'Tring', 'Rowsham', \n",
    "             'Waddesdon', 'Princes Risborough', 'Chinnor', 'Dorton', 'Tetsworth', 'Watlington', \n",
    "             'Chalgrove', 'Little Milton', 'Horton-Cum-Studley', 'Forest Hill', 'Wheatley']\n",
    "\n",
    "# Loop through each location and create a separate plot\n",
    "for location in locations:\n",
    "    # Filter the dataframe for the current location\n",
    "    location_data = tw_da_data_edm[tw_da_data_edm['LocationName'] == location]\n",
    "    \n",
    "    # Replace values above 34 with 34 in the 'AlertType' column\n",
    "    location_data['AlertType'] = location_data['AlertType'].apply(lambda x: 34 if x > 34 else x)\n",
    "    \n",
    "    # Plot the data for the current location\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add bar chart trace for AlertType\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=location_data['DateTime'],\n",
    "        y=location_data['AlertType'],\n",
    "        name='',\n",
    "        marker_color='#673AB7',\n",
    "        marker_line_color='#673AB7',  # Set bar outline color\n",
    "        marker_line_width=1,  # Set bar outline width\n",
    "        width=8  # Adjust the width of the bars\n",
    "    ))\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=f'Timeline of Discharge for EDM - {location}',\n",
    "        xaxis=dict(title='Date/Time', type='date', range=['2022-01-01', '2024-04-30']),\n",
    "        yaxis=dict(title=''),\n",
    "        hovermode='x unified',\n",
    "        xaxis_rangeslider_visible=True,\n",
    "        plot_bgcolor='#B2DFDB'  # Background color\n",
    "    )\n",
    "\n",
    "    # Set the y-axis range to 0-34\n",
    "    fig.update_yaxes(range=[0, 34])\n",
    "\n",
    "    # Add zoom tool to the toolbar\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(visible=True),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51ca5c-dc66-42e5-bf68-b03cc43310f4",
   "metadata": {},
   "source": [
    "* We will use these visuals to analyze the relationship between discharges and the corresponding determinants at various sampling points along the river. Each discharge point will be linked to its respective sampling point, allowing us to comprehensively understand how these discharges influence the determinants at each location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72abcf3-fee6-46b8-bf1f-1fd29e75b26e",
   "metadata": {},
   "source": [
    "### 4.4. Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ad28b-c8f4-44a6-aa3e-c8012f029e85",
   "metadata": {},
   "source": [
    "* Now we will create the features to be used in the app. First, we will filter the data to include only records from the year 2022 to the present. Next, we will focus on specific determinants and exclude others. Finally, we will link the sampling points to the EDMs, rainfall, and flow data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80a66b-0c36-41a8-af7b-d4e608076b7f",
   "metadata": {},
   "source": [
    "#### 4.4.1. Firstly we will reduce our data and look at it from the date 2022 to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934cf94-c5f6-4b0b-bc57-f0d536a91ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec958c1-9443-4c6d-aab1-b99b75d22919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'sample_date_time' column to datetime format\n",
    "wq_wide['sample_date_time'] = pd.to_datetime(wq_wide['sample_date_time'])\n",
    "\n",
    "# Filter data from 2022 onwards\n",
    "filtered_data = wq_wide[wq_wide['sample_date_time'] >= '2022-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae8de9-1fae-466b-8dd7-0a6eba21871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221d900-c8f7-4ca4-9d9f-04fcaf495800",
   "metadata": {},
   "source": [
    "* Now the next focus should be the Sampling Points along the River."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e4ab9-ba52-4186-9bc1-af501d42879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of special sites\n",
    "special_sites = ['TH-PTAE0064', 'TH-PTAE009', 'TH-PTAE0021', 'TH-PTAE0223', 'TH-PTAE0212',\n",
    "                 'TH-PTAE0024', 'TH-PTAR0028', 'TH-PTAR0020', 'TH-PTAR0021', 'TH-PTAR0048',\n",
    "                 'TH-PTAR0112', 'TH-PTAR0132', 'TH-PTAR0030', 'TH-PTAR0100', 'TH-PTAR0052',\n",
    "                 'TH-PTAR0022', 'TH-RSN0914']\n",
    "\n",
    "# Filter the dataframe to include only the special sites\n",
    "filtered_data = filtered_data[filtered_data['sampling_point_notation'].isin(special_sites)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523794f-12b5-430c-8616-aae086f0188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063faaaa-072c-47e9-8424-61fe9e2aa733",
   "metadata": {},
   "source": [
    "* It's apparent that our dataset contains fewer records than anticipated. Now, we need to verify whether each sampling point from the river is still represented in the updated dataset. It's conceivable that certain sampling points may lack the most recent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce2d7a-f613-4635-9b4f-bfe089d83a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each sampling point from special_sites in the filtered dataframe\n",
    "sampling_point_counts = filtered_data['sampling_point_notation'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(sampling_point_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dfcc2-d3cc-400e-be25-693d4cbb9e91",
   "metadata": {},
   "source": [
    "We wanted to examine the counts of each sampling point in the filtered dataset to understand the distribution of data across different sampling points. This interest stemmed from noticing a reduction in the amount of data after filtering the dataset. By calculating the frequency of occurrence for each sampling point, We could gauge the representation of each location in the reduced dataset. The count of occurrences for each sampling point provides valuable insights into the availability and coverage of data. For example, sampling points with higher counts are more frequently observed in the dataset, suggesting a more comprehensive data collection effort or higher monitoring frequency at those locations. Conversely, sampling points with lower counts may indicate a lack of recent data or less frequent sampling. Understanding these counts is crucial for assessing the reliability and completeness of the dataset for further analysis and decision-making processes.\n",
    "\n",
    "Now from this results we can see that the amount of times the data was taken is too low an will make it hard for us te get the exact relationship of effects the other factors such as EDMs, Rain and Flow have an effect on the determinants along the sampling points on the river. So one recormandation we can make is that we need to have samples taken on a more ragular basis than e.g. 28 times in a period of two years.\n",
    "\n",
    "**Now we want to see a new geospacial view of the sampling points.**\n",
    "\n",
    "TH-PTAR0030, TH-PTAR0028, TH-PTAR0022, TH-PTAE0024, TH-PTAR0048, TH-PTAR0021, TH-PTAR0020, TH-PTAE0064, TH-PTAE0021, TH-PTAR0112, TH-RSN0914.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9108de-77e1-4677-9e64-ab8a11587145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling sites with different colors\n",
    "special_sites = ['TH-PTAR0030','TH-PTAR0028', 'TH-PTAR0022', 'TH-PTAE0024', 'TH-PTAR0048', 'TH-PTAR0021', 'TH-PTAR0020', 'TH-PTAE0064', 'TH-PTAE0021', 'TH-PTAR0112', 'TH-RSN0914']\n",
    "\n",
    "filtered_wq = wq_wide[wq_wide['sampling_point_notation'].isin(special_sites)]\n",
    "\n",
    "print(filtered_wq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadad57-2f9d-49b1-a837-acab21e105ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a set to store unique coordinates\n",
    "unique_coordinates = set()\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[wq_wide['latitude'].mean(), wq_wide['longitude'].mean()], zoom_start=10)\n",
    "\n",
    "# Add markers for each unique latitude and longitude point\n",
    "for index, row in filtered_wq.iterrows():\n",
    "    # Check if the coordinates are unique\n",
    "    if (row['latitude'], row['longitude']) not in unique_coordinates:\n",
    "        # Create a popup with the sampling_point_notation\n",
    "        popup = folium.Popup(row['sampling_point_notation'], parse_html=True)\n",
    "        \n",
    "        # Check if the sampling point is special\n",
    "        if row['sampling_point_notation'] in special_sites:\n",
    "            # Add marker with custom color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup, icon=folium.Icon(color='darkblue')).add_to(m)\n",
    "        else:\n",
    "            # Add marker with default color\n",
    "            folium.Marker([row['latitude'], row['longitude']], popup=popup).add_to(m)\n",
    "        \n",
    "        # Add the coordinates to the set\n",
    "        unique_coordinates.add((row['latitude'], row['longitude']))\n",
    "\n",
    "\n",
    "# add thame catchment geojson data\n",
    "geojson_data='../src/thame_catchment.geojson'\n",
    "folium.GeoJson(data=geojson_data).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2849494-6c56-41e8-9586-c46e52f6fa8c",
   "metadata": {},
   "source": [
    "#### 4.4.2. Dropping Unnecessary Determinants\n",
    "* From our analysis we need to drop some determinants that do not affect the data and do not play much of a role in the overrall Health of the River."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf5db5-d51a-42b6-b4a2-da62a91fcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to be dropped\n",
    "columns_to_drop = ['easting', 'northing', 'conductivity', 'iron', 'nitrite', \n",
    "                   'dissolved_oxygen_%_saturation', 'Phosphate']\n",
    "\n",
    "# Drop the specified columns from the dataset\n",
    "filtered_data = filtered_data.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe10666-7ea2-4874-b593-b8a3c66bcc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6fdc8b-0af4-43f0-9243-9ad2a7eeef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b788674-48c0-4dcc-9b2a-31dcb2ce6152",
   "metadata": {},
   "source": [
    "Now that we have reduced the dataset and removed some sampling points, we aim to establish thresholds to determine whether each water quality determinant is within acceptable limits, above, or below. To accomplish this, we referenced information from the Environment Agency (EA), as outlined in the document [provided link](https://www.legislation.gov.uk/uksi/2015/1623/pdfs/uksiod_20151623_en_003.pdf). Additionally, for certain determinants, we relied on international standards, considering the potential for this product to have global applicability. By incorporating these thresholds, we can effectively evaluate water quality parameters and identify instances where they deviate from established standards, ensuring comprehensive monitoring and assessment of environmental conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefee06c-7072-462c-9c0a-a9b46750df84",
   "metadata": {},
   "source": [
    "#### 4.4.3. Threshold values for determinants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fd1a6-2158-41e5-9b1e-268c68ae291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold values for each determinant\n",
    "thresholds = {\n",
    "    'ammoniacal_nitrogen': {'min': 0, 'max': 1},\n",
    "    'bod_atu': {'min': 0, 'max': 4},\n",
    "    'ph': {'min': 6.5, 'max': 8.5},\n",
    "    'nitrogen_oxidised': {'min': 0, 'max': 2},\n",
    "    'nitrate': {'min': 0, 'max': 10},\n",
    "    'orthophosphate': {'min': 0, 'max': 0.1},\n",
    "    'water_temperature_in_celsius': {'min': 10, 'max': 25},\n",
    "    'dissolved_oxygen_O2': {'min': 5, 'max': 10},\n",
    "    'unionised_ammonia': {'min': 0, 'max': 0.5},\n",
    "    'solids_suspended_at_105C': {'min': 0, 'max': 50}\n",
    "}\n",
    "\n",
    "# Initialize a list to store the counts of determinants out of limits\n",
    "out_of_limits_count = []\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for index, row in filtered_data.iterrows():\n",
    "    # Initialize count for determinants out of limits\n",
    "    count_out_of_limits = 0\n",
    "    \n",
    "    # Iterate through each determinant column and check if it's within limits\n",
    "    for determinant, threshold in thresholds.items():\n",
    "        value = row[determinant]\n",
    "        if value < threshold['min'] or value > threshold['max']:\n",
    "            count_out_of_limits += 1\n",
    "    \n",
    "    # Append the count of determinants out of limits for the current row\n",
    "    out_of_limits_count.append(count_out_of_limits)\n",
    "\n",
    "# Add the out of limits count to the dataframe as a new column\n",
    "filtered_data['Out of Limits'] = out_of_limits_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fc47c-e735-447f-8bae-a5c455915d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaecbb2-aa7a-4504-84ca-c82a8bd2365a",
   "metadata": {},
   "source": [
    "#### Facet Plot\n",
    "\n",
    "The next thing we would like to see now is the visuals aligned in a row and having them in this order.\n",
    "\n",
    "##### Determinants\n",
    "- \"ammoniacal_nitrogen\"\n",
    "- \"bod_atu\"\n",
    "- \"solids_suspended_at_105C\"\n",
    "- \"nitrogen_oxidised\"\n",
    "- \"nitrate\"\n",
    "- \"orthophosphate\"\n",
    "- \"dissolved_oxygen_O2\"\n",
    "\n",
    "##### EDMs (Discharge Points)\n",
    "The EDMs that directly affect or flow into the sampling point.\n",
    "\n",
    "##### River Flow\n",
    "Using one set of data from Wheatley.\n",
    "\n",
    "##### Rainfall\n",
    "Using the Mean rainfall data for the catchment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8c7c2-f746-426b-830a-06f342ca7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold values for determinants with units\n",
    "thresholds = {\n",
    "    'ammoniacal_nitrogen': {'min': 0, 'max': 1, 'unit': 'mg/l'},\n",
    "    'bod_atu': {'min': 0, 'max': 4, 'unit': 'mg/l'},\n",
    "    'ph': {'min': 6.5, 'max': 8.5, 'unit': 'phunits'},\n",
    "    'nitrogen_oxidised': {'min': 0, 'max': 2, 'unit': 'mg/l'},\n",
    "    'nitrate': {'min': 0, 'max': 10, 'unit': 'mg/l'},\n",
    "    'orthophosphate': {'min': 0, 'max': 0.1, 'unit': 'mg/l'},\n",
    "    'dissolved_oxygen_O2': {'min': 5, 'max': 10, 'unit': 'mg/l'},\n",
    "    'solids_suspended_at_105C': {'min': 0, 'max': 50, 'unit': 'mg/l'}\n",
    "}\n",
    "\n",
    "# Sampling points and their labels\n",
    "sampling_points = {\n",
    "    'TH-PTAR0030': 'THAME AT WHEATLEY BRIDGE'\n",
    "}\n",
    "\n",
    "# Define determinants\n",
    "determinants = [\n",
    "    \"ammoniacal_nitrogen\", \"bod_atu\", \"solids_suspended_at_105C\", \"nitrogen_oxidised\", \"nitrate\", \"orthophosphate\", \"dissolved_oxygen_O2\"\n",
    "]\n",
    "\n",
    "# Filter data for the range of interest (from 2022 to current date)\n",
    "start_date = datetime.datetime(2022, 1, 1)\n",
    "end_date = datetime.datetime.now()\n",
    "wq_wide_filtered = wq_wide[(wq_wide['sample_date_time'] >= start_date) & (wq_wide['sample_date_time'] <= end_date)]\n",
    "\n",
    "# Create a separate plot for each determinant\n",
    "for determinant in determinants:\n",
    "    # Create empty figure\n",
    "    fig = px.line(title=f'Time Series Plot of {determinant} for Different Sampling Points',\n",
    "                  labels={'sample_date_time': 'Date', 'value': f'Value ({thresholds[determinant][\"unit\"]})'},\n",
    "                  template='plotly_white')\n",
    "\n",
    "    # Add lines for each sampling point\n",
    "    for sample_point, label in sampling_points.items():\n",
    "        # Filter the dataframe for the current sample point\n",
    "        sample_data = wq_wide_filtered[wq_wide_filtered['sampling_point_notation'] == sample_point]\n",
    "\n",
    "        # Plot the data for the current determinant with different colors\n",
    "        fig.add_scatter(x=sample_data['sample_date_time'], y=sample_data[determinant],\n",
    "                        mode='lines', name=label)\n",
    "\n",
    "    # Add threshold lines\n",
    "    fig.add_hline(y=thresholds[determinant][\"min\"], line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Lower Limit ({thresholds[determinant]['min']} {thresholds[determinant]['unit']})\", \n",
    "                  annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=thresholds[determinant][\"max\"], line_dash=\"dash\", line_color=\"red\",\n",
    "                  annotation_text=f\"Upper Limit ({thresholds[determinant]['max']} {thresholds[determinant]['unit']})\", \n",
    "                  annotation_position=\"top right\")\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title='Date', type='date', tickformat='%Y-%m-%d'),\n",
    "        yaxis=dict(title=f'Value ({thresholds[determinant][\"unit\"]})'),\n",
    "        hovermode='x unified',\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        plot_bgcolor='#B2DFDB'  # Set background color\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# List of location names you want to filter by\n",
    "locations = ['Worminghall', 'Forest Hill', 'Wheatley']\n",
    "\n",
    " # EDM Locations linked to each sampling point\n",
    "\n",
    " #    'TH-PTAE0064': ['Wingrave', 'Rowsham'],\n",
    " #    'TH-PTAR0028': ['Stewkley'],\n",
    " #    'TH-PTAR0020': ['Aylesbury', 'Waddesdon'],\n",
    " #    'TH-PTAE0021': ['Cuddington'],\n",
    " #    'TH-PTAR0021': ['Cuddington'],\n",
    " #    'TH-PTAR0048': ['Dorton'],\n",
    " #    'TH-PTAR0112': ['Haddenham', 'Thame'],\n",
    " #    'TH-PTAR0030': ['Worminghall', 'Forest Hill', 'Wheatley'],\n",
    " #    'TH-RSM0914': ['Wheatley', 'Little Milton'],\n",
    " #    'TH-PTAR0022': ['Wheatley', 'Little Milton],\n",
    " #    'TH-PTAE0024': ['Dorchester']\n",
    "\n",
    "# Loop through each location and create a separate plot\n",
    "for location in locations:\n",
    "    # Filter the dataframe for the current location\n",
    "    location_data = tw_da_data_edm[tw_da_data_edm['LocationName'] == location]\n",
    "    \n",
    "    # Replace values above 34 with 34 in the 'AlertType' column\n",
    "    location_data['AlertType'] = location_data['AlertType'].apply(lambda x: 34 if x > 34 else x)\n",
    "    \n",
    "    # Plot the data for the current location\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add bar chart trace for AlertType\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=location_data['DateTime'],\n",
    "        y=location_data['AlertType'],\n",
    "        name='',\n",
    "        marker_color='#673AB7',\n",
    "        marker_line_color='#673AB7',  # Set bar outline color\n",
    "        marker_line_width=1,  # Set bar outline width\n",
    "        width=8  # Adjust the width of the bars\n",
    "    ))\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title=f'Timeline of Events for EDM - {location}',\n",
    "        xaxis=dict(title='Date/Time', type='date', range=['2022-01-01', '2024-04-30']),\n",
    "        yaxis=dict(title=''),\n",
    "        hovermode='x unified',\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        plot_bgcolor='#B2DFDB'  # Background color\n",
    "    )\n",
    "\n",
    "    # Set the y-axis range to 0-34\n",
    "    fig.update_yaxes(range=[0, 34])\n",
    "\n",
    "    # Add zoom tool to the toolbar\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeselector=dict(\n",
    "                buttons=list([\n",
    "                    dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                    dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                    dict(step=\"all\")\n",
    "                ])\n",
    "            ),\n",
    "            rangeslider=dict(visible=False),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# Filter the dataframe for the River Thame area and all dates\n",
    "wheatley_filtered = rfl_wide\n",
    "\n",
    "# Create line chart for the river_thame_mean_river_flow_level\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line for river_thame_mean_river_flow_level\n",
    "fig.add_scatter(x=wheatley_filtered['date'], y=wheatley_filtered['river_thame_river_flow_level'], \n",
    "                mode='lines', name='River Thame Flow Level')\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='River Thame Flow Level',\n",
    "    xaxis=dict(title='Date', type='date', tickformat='%Y-%m-%d'),\n",
    "    yaxis=dict(title='Flow Level'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Filter the dataframe for the Aylesbury and Wheatley areas and all dates\n",
    "filtered_rainfall_data = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line chart trace for the mean rainfall\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=filtered_rainfall_data['date'],\n",
    "    y=filtered_rainfall_data['rain_mean_x'],\n",
    "    mode='lines',\n",
    "    name='Mean Rainfall',\n",
    "    line=dict(color='green')  # Change color to green\n",
    "))\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title='Timeline of Rainfall',\n",
    "    xaxis=dict(title='Date/Time', type='date'),\n",
    "    yaxis=dict(title='Rainfall (mm)'),\n",
    "    hovermode='x unified',\n",
    "    xaxis_rangeslider_visible=False,\n",
    "    plot_bgcolor='#B2DFDB'  # Background color\n",
    ")\n",
    "\n",
    "# Add zoom tool to the toolbar\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    ),\n",
    "    showlegend=False  # Remove the legend\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34728c-918c-4a25-b923-fdb85b76f4a4",
   "metadata": {},
   "source": [
    "* On this visual, we've achieved a neat alignment of the determinants. This arrangement aids in understanding the influences of each factor. We observe that a significant portion of discharges correlates with rainfall and high river flow. Additionally, some determinants appear to be influenced not only by river flow but also by discharges. We intend to incorporate this feature into the app, allowing clients to visualize the interplay between different factors and understand their effects better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5ee4a",
   "metadata": {},
   "source": [
    "<a id=\"nine\"></a>\n",
    "\n",
    "## 5. Conclusions\n",
    "\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "| ⚡ Description: Conclusions ⚡                                                                                                    |\n",
    "| :--------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| In this section we concluded the project. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df97b8d-44aa-46f3-a793-89ef2efee88f",
   "metadata": {},
   "source": [
    "The insights gleaned from the data provide a nuanced understanding of how factors such as sewage discharges, agricultural runoff, and industrial waste directly influence water quality. By examining trends and correlations within the data, users can identify specific indicators that serve as reliable markers for assessing the health of rivers. These indicators may include nutrient levels, presence of pollutants, microbial contamination, and overall biodiversity.\n",
    "\n",
    "Moreover, these insights offer a holistic view of the complex interplay between human activities and natural processes, shedding light on the broader implications for river ecosystems. Armed with this knowledge, stakeholders can develop targeted strategies and policies to mitigate the negative impacts of these factors and restore balance to river ecosystems. Ultimately, these insights serve as a valuable resource for guiding decision-making and fostering sustainable practices that safeguard the health and integrity of our rivers for future generations.\n",
    "\n",
    "Our findings indicate that rivers predominantly receive water from rainfall, with its influence on river flow varying throughout different seasons. Subsequently, heightened rainfall and increased river flow often coincide with the discharge of waste by sewage treatment facilities into rivers. This introduces contaminants, leading to spikes in certain water quality indicators.\n",
    "\n",
    "However, our analysis encountered a challenge. The irregular sampling frequency of water quality data, unlike the consistent monitoring of rainfall and river flow, complicates the attribution of spikes in water quality indicators solely to rainfall, flow, or sewage discharge.\n",
    "\n",
    "Furthermore, examination of data contributed by citizen scientists and the assessment of surrounding land use patterns suggest that runoff from agricultural and urban areas may also contribute to water contamination. This is particularly significant considering the limited availability of sewage discharge data, spanning from late 2023 to early 2024. Consequently, it is plausible that factors other than untreated sewage contributed to fluctuations in water quality indicators prior to this timeframe.\n",
    "\n",
    "We think that further investigation is warranted. By extending the duration of data collection and analysis, we can achieve a more comprehensive understanding of the factors influencing river health.But for the purpose of the POC this is the work we have done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a3809",
   "metadata": {},
   "source": [
    "####  Export preprocessed water quality data to S3 streamlit folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATER QUALITY EXPORT TO S3 STREAMLIT FOLDER\n",
    "\n",
    "key = \"datasets/streamlit_data/streamlit_water_quality_df.csv\"  # Construct the S3 object key\n",
    "csv_buffer = filtered_data.to_csv(None, index=False)  # Generate CSV data as a string\n",
    "s3_client.put_object(Body=csv_buffer, Bucket=S3_BUCKET_NAME, Key=key)  # Upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79643e95",
   "metadata": {},
   "source": [
    "#### Export preprocessed rainfall and river flow data to S3 streamlit folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7a3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAINFALL EXPORT TO S3 STREAMLIT FOLDER\n",
    "\n",
    "# Filter the data for specific dates\n",
    "filtered_rainfall_data = rain_wide[(rain_wide['date'] >= '2022-01-01') & (rain_wide['date'] <= pd.Timestamp.today())]\n",
    "\n",
    "rain_key = \"datasets/streamlit_data/streamlit_rainfall_df.csv\"  # Construct the S3 object key\n",
    "rain_csv_buffer = filtered_rainfall_data.to_csv(None, index=False)  # Generate CSV data as a string\n",
    "s3_client.put_object(Body=rain_csv_buffer, Bucket=S3_BUCKET_NAME, Key=rain_key)  # Upload to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIVER FLOW EXPORT TO S3 STREAMLIT FOLDER\n",
    "\n",
    "rfl_key = \"datasets/streamlit_data/streamlit_river_flow_df.csv\"  # Construct the S3 object key\n",
    "rfl_csv_buffer = rfl_wide.to_csv(None, index=False)  # Generate CSV data as a string\n",
    "s3_client.put_object(Body=rfl_csv_buffer, Bucket=S3_BUCKET_NAME, Key=rfl_key)  # Upload to S3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
